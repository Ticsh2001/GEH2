# visualizer_app.py â€” Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸/Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸

import pandas as pd
import requests
import streamlit as st
import plotly.express as px
import numpy as np
import plotly.graph_objects as go
from typing import List  # Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ° ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚

from code_signal import compute_code_signal, sanitize_numeric_column

st.set_page_config(page_title="Signal Visualizer", layout="wide")
st.title("ğŸ“Š Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²")

query_params = st.query_params
session_token = query_params.get("session", None)
api_url = query_params.get("api_url", "http://localhost:8000")

signal_codes = query_params.get("signals", [])
if isinstance(signal_codes, str):
    signal_codes = [signal_codes]

CODE = ""
if session_token:
    try:
        resp = requests.get(f"{api_url}/api/visualize/session/{session_token}")
        resp.raise_for_status()
        payload = resp.json()
        signal_codes = payload.get("signals", signal_codes)
        CODE = payload.get("code", CODE)
    except Exception as e:
        st.error(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞµÑÑĞ¸Ğ¸: {e}")

if "signals_data" not in st.session_state:
    st.session_state.signals_data = None
if "selected_signals" not in st.session_state:
    st.session_state.selected_signals = set()
if "plot_areas" not in st.session_state:
    st.session_state.plot_areas = []
if "derived_signals" not in st.session_state:
    st.session_state.derived_signals = {}
if "code_signal_name" not in st.session_state:
    st.session_state.code_signal_name = None
if "synthetic_computed" not in st.session_state:
    st.session_state.synthetic_computed = {}  # ÑƒĞ¶Ğµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹
if "signal_groups" not in st.session_state:
    st.session_state.signal_groups = {"project": set(), "dependencies": set()}


def load_base_signals_data(signal_names: List[str]) -> pd.DataFrame | None:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°"""
    if not signal_names:
        return None
    
    try:
        response = requests.post(
            f"{api_url}/api/signal-data",
            json={"signal_names": signal_names, "format": "json"},
        )
        response.raise_for_status()
        result = response.json()
        
        found = result.get("found", [])
        not_found = result.get("not_found", [])
        data_dict = result.get("data", {})
        
        if not_found:
            st.warning(f"âš ï¸ Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ: {', '.join(not_found)}")
        
        if not data_dict:
            return None
        
        frames = []
        for sig, records in data_dict.items():
            if not records:
                continue
            df = pd.DataFrame(records)
            if "datetime" not in df or "value" not in df:
                continue
            df["datetime"] = pd.to_datetime(df["datetime"], errors="coerce")
            df = df.dropna(subset=["datetime"])
            df = df.set_index("datetime").sort_index()
            df = df.rename(columns={"value": sig})
            frames.append(df[[sig]])
        
        if not frames:
            return None
        
        return pd.concat(frames, axis=1).sort_index()
    
    except Exception as exc:
        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²: {exc}")
        return None


# visualizer_app.py â€” Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ resolve_and_load_all_signals

def resolve_and_load_all_signals(input_signals: List[str]) -> tuple[pd.DataFrame | None, List[str], List[str]]:
    """
    Ğ Ğ°Ğ·Ğ²Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ²ÑĞµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ (Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ + ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ).
    
    Returns:
        df_all: DataFrame ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ°Ğ¼Ğ¸
        found: ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²
        not_found: ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ½ĞµĞ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²
    """
    if not input_signals:
        return None, [], []
    
    try:
        # 1. Ğ Ğ°Ğ·Ğ²Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ‡ĞµÑ€ĞµĞ· API
        with st.spinner("ğŸ” Ğ Ğ°Ğ·Ğ²Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²..."):
            resolve_resp = requests.post(
                f"{api_url}/api/resolve-signals",
                json={"signals": input_signals}
            )
            resolve_resp.raise_for_status()
            resolve_data = resolve_resp.json()
        
        base_signals = resolve_data.get("base_signals", [])
        synthetic_signals = resolve_data.get("synthetic_signals", {})
        computation_order = resolve_data.get("computation_order", [])
        
        # === Ğ¡ĞĞ¥Ğ ĞĞĞ¯Ğ•Ğœ Ğ“Ğ Ğ£ĞŸĞŸĞ˜Ğ ĞĞ’ĞšĞ£ Ğ¡Ğ˜Ğ“ĞĞĞ›ĞĞ’ ===
        # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° (Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ)
        project_signals = set(input_signals)
        
        # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ¸Ğ· Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ (Ğ²ÑĞµ Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ)
        dependency_signals = set()
        for syn_name, syn_data in synthetic_signals.items():
            if syn_name not in project_signals:
                dependency_signals.add(syn_name)
            for dep in syn_data.get("dependencies", []):
                if dep not in project_signals:
                    dependency_signals.add(dep)
        
        # Ğ¢Ğ°ĞºĞ¶Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğµ Ğ¸Ğ· Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
        for bs in base_signals:
            if bs not in project_signals:
                dependency_signals.add(bs)
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² session_state Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² ÑĞ°Ğ¹Ğ´Ğ±Ğ°Ñ€Ğµ
        st.session_state.signal_groups = {
            "project": project_signals,       # Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
            "dependencies": dependency_signals # ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ²Ñ‘Ñ€Ğ½ÑƒÑ‚Ñ‹Ñ… Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
        }
        
        st.info(f"ğŸ“Š Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°: {len(project_signals)} | Ğ˜Ğ· Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹: {len(dependency_signals)}")
        
        if synthetic_signals:
            with st.expander("ğŸ”— Ğ“Ñ€Ğ°Ñ„ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²"):
                for syn_name in computation_order:
                    deps = synthetic_signals[syn_name].get("dependencies", [])
                    marker = "ğŸ“Œ" if syn_name in project_signals else "ğŸ”—"
                    st.text(f"  {marker} {syn_name} â† {deps}")
        
        # 2. Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹
        df_all = None
        found_signals = []
        not_found_signals = []
        
        if base_signals:
            with st.spinner(f"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ {len(base_signals)} Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²..."):
                df_all = load_base_signals_data(base_signals)
                if df_all is not None:
                    found_signals = list(df_all.columns)
                    not_found_signals = [s for s in base_signals if s not in df_all.columns]
        
        if df_all is None:
            df_all = pd.DataFrame()
        
        # 3. Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ
        if computation_order:
            with st.spinner(f"âš™ï¸ Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ {len(computation_order)} ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²..."):
                progress_bar = st.progress(0)
                
                for idx, syn_name in enumerate(computation_order):
                    syn_data = synthetic_signals[syn_name]
                    formula = syn_data.get("formula", "")
                    
                    if not formula:
                        st.warning(f"âš ï¸ Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ» '{syn_name}' Ğ½Ğµ Ğ¸Ğ¼ĞµĞµÑ‚ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ñ‹")
                        continue
                    
                    if df_all.empty:
                        st.warning(f"âš ï¸ ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ '{syn_name}'")
                        continue
                    
                    try:
                        syn_series = compute_code_signal(
                            formula,
                            df_all,
                            warn_callback=lambda msg, name=syn_name: st.warning(f"[{name}] {msg}", icon="âš ï¸")
                        )
                        syn_series.name = syn_name
                        df_all[syn_name] = syn_series
                        found_signals.append(syn_name)
                        st.session_state.synthetic_computed[syn_name] = formula
                        
                    except Exception as e:
                        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ '{syn_name}': {e}")
                        not_found_signals.append(syn_name)
                    
                    progress_bar.progress((idx + 1) / len(computation_order))
                
                progress_bar.empty()
        
        return df_all if not df_all.empty else None, found_signals, not_found_signals
    
    except requests.exceptions.HTTPError as http_err:
        error_detail = ""
        try:
            error_detail = http_err.response.json().get("detail", "")
        except:
            pass
        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° API: {error_detail or http_err}")
        return None, [], []
    except Exception as exc:
        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {exc}")
        import traceback
        st.code(traceback.format_exc())
        return None, [], []


# ========== Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ”ĞĞĞĞ«Ğ¥ ==========
if signal_codes and st.session_state.signals_data is None:
    df_base, found_codes, not_found_codes = resolve_and_load_all_signals(signal_codes)
    st.session_state.signals_data = df_base
    
    if found_codes:
        st.success(f"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²: {len(found_codes)}")
    if not_found_codes:
        st.warning(f"âš ï¸ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹: {', '.join(not_found_codes)}")


# --- Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ĞºĞ¾Ğ´ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹, Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ñ get_all_signals_df ---

def get_all_signals_df(exclude: set[str] | None = None):
    exclude = exclude or set()
    base = st.session_state.signals_data
    derived = st.session_state.derived_signals

    dfs = []
    if base is not None:
        dfs.append(base)
    for name, ddf in derived.items():
        if name in exclude:
            continue
        dfs.append(ddf)

    if not dfs:
        return None
    return pd.concat(dfs, axis=1).sort_index()


def compute_stats_numeric(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()

    numeric = df.apply(sanitize_numeric_column)
    valid_cols = [col for col in numeric.columns if numeric[col].count() > 0]
    if not valid_cols:
        return pd.DataFrame()

    numeric = numeric[valid_cols]
    stats = pd.DataFrame(index=numeric.columns)
    stats["count"] = numeric.count()
    stats["min"] = numeric.min()
    stats["max"] = numeric.max()
    stats["mean"] = numeric.mean()
    stats["std"] = numeric.std()
    stats["median"] = numeric.median()

    starts, ends = [], []
    for col in numeric.columns:
        series = numeric[col].dropna()
        starts.append(series.index.min() if not series.empty else pd.NaT)
        ends.append(series.index.max() if not series.empty else pd.NaT)

    stats["start"] = starts
    stats["end"] = ends
    return stats


def make_unique_name(base_name: str) -> str:
    existing = set()
    if st.session_state.signals_data is not None:
        existing |= set(st.session_state.signals_data.columns)
    existing |= set(st.session_state.derived_signals.keys())
    if base_name not in existing:
        return base_name
    idx = 2
    while f"{base_name}_{idx}" in existing:
        idx += 1
    return f"{base_name}_{idx}"


if signal_codes and st.session_state.signals_data is None:
    with st.spinner("Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²..."):
        df_all, found_codes, not_found_codes = resolve_and_load_all_signals(signal_codes)
        st.success(f"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²: {len(found_codes)}")
        if not_found_codes:
            st.warning(f"âš ï¸ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹: {', '.join(not_found_codes)}")

# --- ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¸Ğ· CODE (ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ Ğ½Ğµ Ğ¿ĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼) ---
code_signal_name = st.session_state.code_signal_name
df_for_code = get_all_signals_df(exclude={code_signal_name} if code_signal_name else None)

# ĞšĞ»ÑÑ‡ "ĞºĞ°ĞºĞ¾Ğ¹ CODE Ğ¼Ñ‹ ÑƒĞ¶Ğµ ÑÑ‡Ğ¸Ñ‚Ğ°Ğ»Ğ¸" (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ CODE; session_token Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ» Ğ½Ğ° Ğ²ÑÑĞºĞ¸Ğ¹)
code_key = (session_token, CODE)

already_have_series = (
    st.session_state.code_signal_name is not None
    and st.session_state.code_signal_name in st.session_state.derived_signals
)

if CODE and df_for_code is not None:
    need_recalc = (st.session_state.get("code_key") != code_key) or (not already_have_series)

    if need_recalc:
        try:
            synthetic_series = compute_code_signal(
                CODE,
                df_for_code,
                warn_callback=lambda msg: st.warning(msg, icon="âš ï¸"),
            )
            target_name = code_signal_name or make_unique_name("CODE_RESULT")
            synthetic_series.name = target_name

            st.session_state.derived_signals[target_name] = pd.DataFrame({target_name: synthetic_series})
            st.session_state.code_signal_name = target_name
            st.session_state.selected_signals.add(target_name)

            st.session_state.code_key = code_key
            st.success(f"Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½: {target_name}")
        except Exception as exc:
            st.warning(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ÑŒ CODE: {exc}")

elif not CODE:
    # ĞµÑĞ»Ğ¸ CODE Ğ¸ÑÑ‡ĞµĞ· â€” ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¸ ÑĞ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ ĞºĞ»ÑÑ‡
    if code_signal_name:
        st.session_state.derived_signals.pop(code_signal_name, None)
        st.session_state.selected_signals.discard(code_signal_name)
        st.session_state.code_signal_name = None
    st.session_state.code_key = None

# --- Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ DataFrame ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ°Ğ¼Ğ¸ ---
df_all_signals = get_all_signals_df()

with st.sidebar:
    st.header("Ğ’Ñ‹Ğ±Ğ¾Ñ€ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²")

    if df_all_signals is not None:
        available_signals = df_all_signals.columns.tolist()
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²
        signal_groups = st.session_state.get("signal_groups", {
            "project": set(available_signals),
            "dependencies": set()
        })
        
        project_signals = [s for s in available_signals if s in signal_groups.get("project", set())]
        dependency_signals = [s for s in available_signals if s in signal_groups.get("dependencies", set())]
        
        # === Ğ¡Ğ˜Ğ“ĞĞĞ›Ğ« ĞŸĞ ĞĞ•ĞšĞ¢Ğ ===
        if project_signals:
            st.subheader("ğŸ“Œ Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°")
            for signal in project_signals:
                # ĞŸĞ¾Ğ¼ĞµÑ‡Ğ°ĞµĞ¼ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹
                is_synthetic = signal in st.session_state.get("synthetic_computed", {})
                label = f"âš™ï¸ {signal}" if is_synthetic else signal
                
                checked = st.checkbox(
                    label,
                    value=(signal in st.session_state.selected_signals),
                    key=f"proj_{signal}"
                )
                if checked:
                    st.session_state.selected_signals.add(signal)
                else:
                    st.session_state.selected_signals.discard(signal)
        
        # === Ğ¡Ğ˜Ğ“ĞĞĞ›Ğ« Ğ˜Ğ— Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞĞ¡Ğ¢Ğ•Ğ™ ===
        if dependency_signals:
            st.divider()
            with st.expander(f"ğŸ”— Ğ˜Ğ· Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ ({len(dependency_signals)})", expanded=False):
                for signal in dependency_signals:
                    is_synthetic = signal in st.session_state.get("synthetic_computed", {})
                    label = f"âš™ï¸ {signal}" if is_synthetic else signal
                    
                    checked = st.checkbox(
                        label,
                        value=(signal in st.session_state.selected_signals),
                        key=f"dep_{signal}"
                    )
                    if checked:
                        st.session_state.selected_signals.add(signal)
                    else:
                        st.session_state.selected_signals.discard(signal)
        
        # === Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ ===
        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… Ğ’ÑĞµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°"):
                st.session_state.selected_signals.update(project_signals)
                st.rerun()
        with col2:
            if st.button("âŒ Ğ¡Ğ½ÑÑ‚ÑŒ Ğ²ÑĞµ"):
                st.session_state.selected_signals.clear()
                st.rerun()

        st.divider()
        st.subheader("Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»")

        base_df = st.session_state.signals_data
        if base_df is not None and not base_df.empty:
            base_choice = st.selectbox("Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»", base_df.columns)
            series = base_df[base_choice].dropna()
            if not series.empty:
                col1, col2 = st.columns(2)
                with col1:
                    start_date = st.date_input(
                        "ĞĞ°Ñ‡Ğ°Ğ»Ğ¾",
                        value=series.index.min().date(),
                    )
                with col2:
                    end_date = st.date_input(
                        "ĞšĞ¾Ğ½ĞµÑ†",
                        value=series.index.max().date(),
                    )

                start_ts = pd.Timestamp(start_date)
                end_ts = pd.Timestamp(end_date) + pd.Timedelta(days=1) - pd.Timedelta(
                    microseconds=1
                )

                default_name = f"{base_choice}__{start_ts.date()}_{end_ts.date()}"
                new_name = st.text_input("Ğ˜Ğ¼Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ°", value=default_name)

                col3, col4 = st.columns(2)
                if col3.button("Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ"):
                    name_unique = make_unique_name(new_name.strip())
                    cut_series = series[(series.index >= start_ts) & (series.index <= end_ts)]
                    if cut_series.empty:
                        st.warning("Ğ’ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ Ğ½ĞµÑ‚ Ñ‚Ğ¾Ñ‡ĞµĞº.")
                    else:
                        st.session_state.derived_signals[name_unique] = pd.DataFrame(
                            {name_unique: cut_series}
                        )
                        st.success(f"Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»: {name_unique}")
                        st.rerun()
                if col4.button("ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ"):
                    st.session_state.derived_signals = {
                        k: v
                        for k, v in st.session_state.derived_signals.items()
                        if k == st.session_state.code_signal_name
                    }
                    st.session_state.selected_signals = {
                        sig
                        for sig in st.session_state.selected_signals
                        if (st.session_state.signals_data is not None and sig in st.session_state.signals_data.columns)
                        or sig == st.session_state.code_signal_name
                    }
                    st.rerun()

        if st.session_state.derived_signals:
            st.subheader("Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¹/ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»")
            derived_names = [name for name in st.session_state.derived_signals.keys()]
            delete_candidate = st.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ", ["â€”"] + derived_names)
            if st.button("Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹") and delete_candidate != "â€”":
                st.session_state.derived_signals.pop(delete_candidate, None)
                st.session_state.selected_signals.discard(delete_candidate)
                if delete_candidate == st.session_state.code_signal_name:
                    st.session_state.code_signal_name = None
                st.rerun()

        st.divider()
        st.subheader("ĞĞ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ")
        col_a, col_b = st.columns(2)
        if col_a.button("â• Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº"):
            new_id = max([area.get("id", 0) for area in st.session_state.plot_areas] + [0]) + 1
            st.session_state.plot_areas.append({"id": new_id, "signals": []})
            st.rerun()
        if col_b.button("âŒ ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ"):
            st.session_state.plot_areas = []
            st.session_state.selected_signals = set()
            st.rerun()
    else:
        st.info("ğŸ“¥ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² ĞµÑ‰Ğµ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹.")

if df_all_signals is not None and st.session_state.selected_signals:
    if not st.session_state.plot_areas:
        st.session_state.plot_areas.append(
            {"id": 1, "signals": list(st.session_state.selected_signals)}
        )

    for i, plot_area in enumerate(st.session_state.plot_areas):
        with st.container():
            col1, col2 = st.columns([3, 1])
            with col1:
                st.subheader(f"Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº #{plot_area['id']}")
            with col2:
                if st.button("Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ", key=f"remove_area_{i}"):
                    st.session_state.plot_areas.pop(i)
                    st.rerun()

            selected = st.multiselect(
                "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»(Ñ‹):",
                list(st.session_state.selected_signals),
                default=plot_area.get("signals", []),
                key=f"signals_sel_{i}",
            )
            st.session_state.plot_areas[i]["signals"] = selected

            if selected:
                df_plot = df_all_signals[selected].copy()

                # Ğ”Ğ»Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ñ‡Ğ¸ÑĞ»Ğ°Ğ¼ (Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ñ…)
                df_plot_num = df_plot.apply(sanitize_numeric_column)

                valid_index = df_plot_num.dropna(how="all").index
                if len(valid_index) == 0:
                    st.warning("ĞĞµÑ‚ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ².")
                else:
                    ts_idx = st.slider(
                        "Ğ’ĞµÑ€Ñ‚Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¸Ğ½Ğ¸Ñ (Ğ²Ñ€ĞµĞ¼Ñ)",
                        min_value=0,
                        max_value=len(valid_index) - 1,
                        value=len(valid_index) - 1,
                        key=f"vline_{i}",
                    )
                    ts = valid_index[ts_idx]

                    # Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº Ñ Ğ²ĞµÑ€Ñ‚Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ»Ğ¸Ğ½Ğ¸ĞµĞ¹
                    fig = px.line(
                        df_plot_num,
                        x=df_plot_num.index,
                        y=selected,
                        title=f"Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº #{plot_area['id']}",
                        render_mode="webgl"
                    )
                    fig.add_vline(x=ts, line_width=2, line_dash="dash", line_color="red")
                    fig.update_layout(
                        uirevision=f"plot_area_{plot_area['id']}",
                        height=650,
                        legend_title_text="Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»Ñ‹",
                        xaxis_title="Ğ’Ñ€ĞµĞ¼Ñ",
                        yaxis_title="Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ",
                        margin=dict(l=20, r=20, t=40, b=20),
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    # Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ»Ğ¸Ğ½Ğ¸Ğ¸
                    nearest = df_plot_num.reindex(df_plot_num.index.union([ts])).sort_index()
                    nearest = nearest.ffill().loc[ts]

                    # ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° + ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ»Ğ¸Ğ½Ğ¸Ğ¸
                    st.markdown("**ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° (Ğ¿Ğ¾ Ğ²ÑĞµĞ¼Ñƒ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñƒ):**")
                    stats_df = compute_stats_numeric(df_plot)
                    if stats_df.empty:
                        st.info("ĞĞµÑ‚ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ñ€Ğ°ÑÑ‡Ñ‘Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸.")
                    else:
                        stats_view = stats_df.copy()
                        stats_view["value"] = nearest.reindex(stats_view.index)
                        stats_view["start"] = (
                            pd.to_datetime(stats_view["start"], errors="coerce")
                            .dt.strftime("%Y-%m-%d %H:%M:%S")
                        )
                        stats_view["end"] = (
                            pd.to_datetime(stats_view["end"], errors="coerce")
                            .dt.strftime("%Y-%m-%d %H:%M:%S")
                        )
                        st.dataframe(
                            stats_view.style.format(
                                {
                                    "count": "{:.0f}",
                                    "min": "{:.6g}",
                                    "max": "{:.6g}",
                                    "mean": "{:.6g}",
                                    "std": "{:.6g}",
                                    "median": "{:.6g}",
                                    "value_at_line": "{:.6g}",
                                },
                                na_rep="",
                            ),
                            use_container_width=True,
                        )
            else:
                st.info("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.")
        st.divider()

elif df_all_signals is None:
    st.info("ğŸ“¥ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² ĞµÑ‰Ñ‘ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹.")
else:
    st.info("ğŸ‘ˆ Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ ÑĞ»ĞµĞ²Ğ° Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.")

if df_all_signals is not None:
    with st.expander("â„¹ï¸ Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Ğ’ÑĞµĞ³Ğ¾ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² (Ğ²ĞºĞ». Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ/ÑĞ¸Ğ½Ñ‚ĞµÑ‚.)", len(df_all_signals.columns))
        with col2:
            st.metric("ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹", len(df_all_signals))
        with col3:
            try:
                dt_range = df_all_signals.index.max() - df_all_signals.index.min()
                st.metric("Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸", str(dt_range).split(".")[0])
            except Exception:
                st.metric("Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸", "â€”")

if CODE:
    with st.expander("ğŸ§© Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´ (Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»)"):
        st.code(CODE, language="text")