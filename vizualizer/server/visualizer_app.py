# visualizer_app.py ‚Äî —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è

import pandas as pd
import requests
import streamlit as st
import plotly.express as px
import numpy as np
import plotly.graph_objects as go
from typing import List
from datetime import datetime, time
from io import BytesIO
from code_signal import register_tables

from code_signal import compute_code_signal, sanitize_numeric_column, evaluate_code_expression, CodeEvaluationError
from visualizer_state import (
    create_visualizer_state, 
    load_visualizer_state,
    STATE_VERSION
)

def _compute_r2(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ R^2."""
    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)
    if mask.sum() < 2:
        return np.nan
    yt = y_true[mask]
    yp = y_pred[mask]
    ss_res = np.sum((yt - yp) ** 2)
    ss_tot = np.sum((yt - yt.mean()) ** 2)
    if ss_tot == 0:
        return np.nan
    return 1.0 - ss_res / ss_tot


def fit_linear(x: np.ndarray, y: np.ndarray) -> dict:
    """–õ–∏–Ω–µ–π–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è y = a + b*x."""
    mask = ~np.isnan(x) & ~np.isnan(y)
    if mask.sum() < 2:
        return {"a": np.nan, "b": np.nan, "r2": np.nan, "y_pred": np.full_like(y, np.nan)}
    coeffs = np.polyfit(x[mask], y[mask], 1)  # [b, a]
    b, a = coeffs[0], coeffs[1]
    y_pred = a + b * x
    r2 = _compute_r2(y, y_pred)
    return {"a": a, "b": b, "r2": r2, "y_pred": y_pred}


def fit_polynomial(x: np.ndarray, y: np.ndarray, degree: int) -> dict:
    """–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è —Å—Ç–µ–ø–µ–Ω–∏ N: y = Œ£ c_k * x^k (k=0..N)."""
    degree = max(1, int(degree))
    mask = ~np.isnan(x) & ~np.isnan(y)
    if mask.sum() <= degree:
        return {"coeffs": None, "r2": np.nan, "y_pred": np.full_like(y, np.nan)}
    coeffs = np.polyfit(x[mask], y[mask], degree)  # —Å—Ç–∞—Ä—à–∏–π ‚Üí –º–ª–∞–¥—à–∏–π
    y_pred = np.polyval(coeffs, x)
    r2 = _compute_r2(y, y_pred)
    return {"coeffs": coeffs, "r2": r2, "y_pred": y_pred}


def fit_power_law(x: np.ndarray, y: np.ndarray) -> dict:
    """
    –°—Ç–µ–ø–µ–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å: y = a * x^p.
    –§–∏—Ç –¥–µ–ª–∞–µ—Ç—Å—è –≤ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ: ln(y) = ln(a) + p*ln(x).
    –¢—Ä–µ–±—É–µ—Ç x > 0 –∏ y > 0.
    """
    mask = (~np.isnan(x)) & (~np.isnan(y)) & (x > 0) & (y > 0)
    if mask.sum() < 2:
        return {"a": np.nan, "p": np.nan, "r2": np.nan, "y_pred": np.full_like(y, np.nan), "used_points": 0}
    lx = np.log(x[mask])
    ly = np.log(y[mask])
    coeffs = np.polyfit(lx, ly, 1)  # [p, ln(a)]
    p, ln_a = coeffs[0], coeffs[1]
    a = float(np.exp(ln_a))
    y_pred = a * np.power(x, p)
    r2 = _compute_r2(y, y_pred)
    return {"a": a, "p": p, "r2": r2, "y_pred": y_pred, "used_points": int(mask.sum())}


def _format_poly_equation(coeffs: np.ndarray, x_name: str, y_name: str) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–∏–Ω–æ–º: y = c0 + c1*x + c2*x^2 + ...
    coeffs: [cN, ..., c1, c0] ‚Äî –ø–æ—Ä—è–¥–æ–∫ Polyfit (—Å—Ç–∞—Ä—à–∏–µ ‚Üí –º–ª–∞–¥—à–∏–µ)
    """
    if coeffs is None or len(coeffs) == 0:
        return f"{y_name} = NaN"
    terms = []
    deg = len(coeffs) - 1
    for i, c in enumerate(coeffs):
        k = deg - i  # —Å—Ç–µ–ø–µ–Ω—å
        coef = f"{c:.6g}"
        if k == 0:
            terms.append(f"{coef}")
        elif k == 1:
            terms.append(f"{coef}¬∑{x_name}")
        else:
            terms.append(f"{coef}¬∑{x_name}^{k}")
    return f"{y_name} = " + " + ".join(terms)


def compute_streaming_signal_streaming_forward(
    formula: str,
    df_base: pd.DataFrame,
    signal_name: str,
) -> pd.Series:
    """
    –ü–æ—Ç–æ–∫–æ–≤—ã–π (–æ–¥–Ω–æ–ø—Ä–æ—Ö–æ–¥–Ω—ã–π) —Ä–∞—Å—á—ë—Ç —Å–∞–º–æ—Å—Å—ã–ª–∞—é—â–µ–≥–æ—Å—è —Å–∏–≥–Ω–∞–ª–∞.
    –ò–¥—ë–º –ø–æ –∏–Ω–¥–µ–∫—Å—É —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ, –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –ø–æ–¥–∞—ë–º —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—É—é
    —á–∞—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ (–¥–ª—è PREV/HISTORY –æ—Ç —Å–∞–º–æ–≥–æ —Å–µ–±—è).
    """
    # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –∏–Ω–¥–µ–∫—Å
    df_work = df_base.copy()
    idx = df_work.index
    n = len(idx)

    # –ë—É—Ñ–µ—Ä –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    result = pd.Series(np.nan, index=idx, name=signal_name)

    # –ò–¥—ë–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
    for i in range(n):
        # –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞ (–¥–æ —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞)
        df_work_current = df_work.iloc[: i + 1].copy()
        df_work_current[signal_name] = result.iloc[: i].reindex(df_work_current.index)
        # –í —Ç–µ–∫—É—â–µ–º —à–∞–≥–µ –µ—â—ë –Ω–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è -> –ø—É—Å—Ç—å –±—É–¥–µ—Ç NaN –Ω–∞ –∫–æ–Ω—Ü–µ
        # evaluate_code_expression –ø–æ—Å—á–∏—Ç–∞–µ—Ç –≤–µ—Å—å –∫—É—Å–æ–∫ –¥–æ —Ç–µ–∫—É—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        try:
            series_step, _ = evaluate_code_expression(formula, df_work_current)
        except Exception as e:
            raise CodeEvaluationError(f"–û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ {i} ({idx[i]}): {e}") from e

        # –ë–µ—Ä—ë–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —Ç–µ–∫—É—â–µ–π —Ç–æ—á–∫–µ –≤—Ä–µ–º–µ–Ω–∏
        val_i = series_step.iloc[-1]
        result.iat[i] = val_i

    return result

def compute_streaming_signal(
    formula: str,
    df_base: pd.DataFrame,
    signal_name: str,
) -> pd.Series:
    """
    –ü–æ—Ç–æ–∫–æ–≤—ã–π —Ä–∞—Å—á—ë—Ç —Å–∞–º–æ—Å—Å—ã–ª–∞—é—â–µ–≥–æ—Å—è —Å–∏–≥–Ω–∞–ª–∞.
    –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É–∂–µ –≤ df_base (–ø–æ—Å—á–∏—Ç–∞–Ω—ã –ø–∞–∫–µ—Ç–Ω–æ).
    –û–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ –ø–æ —Å—Ç—Ä–æ–∫–∞–º, O(n).
    """
    import re
    from code_signal import sanitize_numeric_column
    from code_signal import TABLE_REGISTRY
    from code_signal import _get_xy_from_table, _interp_1d

    df_work = df_base.copy()
    df_work[signal_name] = np.nan

    index = df_work.index
    n = len(index)

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –æ–¥–∏–Ω —Ä–∞–∑
    for col in df_work.columns:
        df_work[col] = sanitize_numeric_column(df_work[col])

    result = np.full(n, np.nan, dtype=np.float64)

    # numpy-–º–∞—Å—Å–∏–≤—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    col_arrays = {}
    for col in df_work.columns:
        col_arrays[col] = df_work[col].values
    col_arrays[signal_name] = result

    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∏–º–µ–Ω–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
    safe_name_map = {}
    used_safe = set()
    sorted_signals = sorted(col_arrays.keys(), key=len, reverse=True)

    for idx_s, sig in enumerate(sorted_signals):
        base = re.sub(r"\W", "_", sig)
        if not base or not re.match(r"[A-Za-z_]", base):
            base = f"SIG_{idx_s}"
        while base in used_safe:
            base += "_"
        used_safe.add(base)
        safe_name_map[sig] = base

    # –ó–∞–º–µ–Ω–∞ –∏–º—ë–Ω —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ —Ñ–æ—Ä–º—É–ª–µ
    def replace_signal_names(expr):
        parts = []
        pos = 0
        in_str = False
        str_ch = ""
        while pos < len(expr):
            ch = expr[pos]
            if in_str:
                parts.append(ch)
                if ch == str_ch and (pos == 0 or expr[pos - 1] != "\\"):
                    in_str = False
                pos += 1
                continue
            if ch in ("'", '"'):
                in_str = True
                str_ch = ch
                parts.append(ch)
                pos += 1
                continue
            matched = None
            for name in sorted_signals:
                if expr.startswith(name, pos):
                    matched = name
                    break
            if matched:
                parts.append(safe_name_map[matched])
                pos += len(matched)
            else:
                parts.append(ch)
                pos += 1
        return "".join(parts)

    def normalize_expr(expr):
        expr = re.sub(r"\bAND\b", "&", expr, flags=re.IGNORECASE)
        expr = re.sub(r"\bOR\b", "|", expr, flags=re.IGNORECASE)
        expr = re.sub(r"\bNOT\b", "~", expr, flags=re.IGNORECASE)
        expr = expr.replace("<>", "!=")
        expr = re.sub(r"(?<![<>=!])=(?![<>=])", "==", expr)
        return expr

    normalized = normalize_expr(formula)
    safe_formula = replace_signal_names(normalized)

    safe_self = safe_name_map[signal_name]

    # =========================================================================
    # –ü–æ–¥–º–µ–Ω–∞ PREV / HISTORY*(self, period) ‚Üí —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
    # =========================================================================

    # PREV(self) ‚Üí __prev_self__
    safe_formula = re.sub(
        r"PREV\s*\(\s*" + re.escape(safe_self) + r"\s*\)",
        "__prev_self__",
        safe_formula,
        flags=re.IGNORECASE,
    )

    # PREV(other_signal) ‚Üí __prev_OTHER__
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ PREV(safe_name) –∫—Ä–æ–º–µ self
    prev_other_map = {}
    for orig, safe in safe_name_map.items():
        if orig == signal_name:
            continue
        pat = re.compile(
            r"PREV\s*\(\s*" + re.escape(safe) + r"\s*\)", re.IGNORECASE
        )
        token = f"__prev_{safe}__"
        if pat.search(safe_formula):
            prev_other_map[orig] = token
            safe_formula = pat.sub(token, safe_formula)

    # HISTORY*(self, period) ‚Üí __history{func}_self_{period}__
    history_self_specs = []  # (func_name, period, token)
    for func_name in [
        "HISTORYAVG", "HISTORYSUM", "HISTORYCOUNT",
        "HISTORYMAX", "HISTORYMIN", "HISTORYDIFF", "HISTORYGRADIENT",
    ]:
        pat = re.compile(
            func_name + r"\s*\(\s*" + re.escape(safe_self) + r"\s*,\s*(\d+)\s*\)",
            re.IGNORECASE,
        )
        for m in pat.finditer(safe_formula):
            period = int(m.group(1))
            token = f"__hist_{func_name}_{period}__"
            history_self_specs.append((func_name, period, token))
        safe_formula = pat.sub(
            lambda m: f"__hist_{func_name}_{int(m.group(1))}__",
            safe_formula,
        )

    # HISTORY*(other, period) ‚Üí __history{func}_other_{period}__
    history_other_specs = []  # (func_name, orig_signal, period, token)
    for orig, safe in safe_name_map.items():
        if orig == signal_name:
            continue
        for func_name in [
            "HISTORYAVG", "HISTORYSUM", "HISTORYCOUNT",
            "HISTORYMAX", "HISTORYMIN", "HISTORYDIFF", "HISTORYGRADIENT",
        ]:
            pat = re.compile(
                func_name + r"\s*\(\s*" + re.escape(safe) + r"\s*,\s*(\d+)\s*\)",
                re.IGNORECASE,
            )
            for m in pat.finditer(safe_formula):
                period = int(m.group(1))
                token = f"__hist_{func_name}_{safe}_{period}__"
                history_other_specs.append((func_name, orig, period, token))
            safe_formula = pat.sub(
                lambda m, fn=func_name, s=safe: f"__hist_{fn}_{s}_{int(m.group(1))}__",
                safe_formula,
            )

    # GETPOINT ‚Üí NaN
    #safe_formula = re.sub(
    #    r"GETPOINT\s*\([^)]*\)", "np.nan", safe_formula, flags=re.IGNORECASE
    #)

    # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –æ–¥–∏–Ω —Ä–∞–∑
    compiled = compile(safe_formula, "<streaming_formula>", "eval")

    # =========================================================================
    # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ HISTORY –¥–ª—è –ù–ï-self —Å–∏–≥–Ω–∞–ª–æ–≤ (–æ–Ω–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–≤–µ—Å—Ç–Ω—ã)
    # =========================================================================
    precomputed_history_other = {}
    for func_name, orig, period, token in history_other_specs:
        arr = col_arrays[orig]
        series = pd.Series(arr, index=index)
        if func_name == "HISTORYAVG":
            rolled = series.rolling(period, min_periods=1).mean()
        elif func_name == "HISTORYSUM":
            rolled = series.rolling(period, min_periods=1).sum()
        elif func_name == "HISTORYCOUNT":
            rolled = series.rolling(period, min_periods=1).count()
        elif func_name == "HISTORYMAX":
            rolled = series.rolling(period, min_periods=1).max()
        elif func_name == "HISTORYMIN":
            rolled = series.rolling(period, min_periods=1).min()
        elif func_name == "HISTORYDIFF":
            r_max = series.rolling(period, min_periods=1).max()
            r_min = series.rolling(period, min_periods=1).min()
            rolled = r_max - r_min
        elif func_name == "HISTORYGRADIENT":
            rolled = _precompute_gradient(series, period)
        else:
            rolled = pd.Series(np.nan, index=index)
        precomputed_history_other[token] = rolled.values

    # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ PREV –¥–ª—è –ù–ï-self —Å–∏–≥–Ω–∞–ª–æ–≤
    precomputed_prev_other = {}
    for orig, token in prev_other_map.items():
        arr = col_arrays[orig]
        shifted = np.empty(n, dtype=np.float64)
        shifted[0] = np.nan
        shifted[1:] = arr[:-1]
        precomputed_prev_other[token] = shifted

    # =========================================================================
    # –ö–æ–ª—å—Ü–µ–≤—ã–µ –±—É—Ñ–µ—Ä—ã –¥–ª—è HISTORY*(self)
    # =========================================================================
    ring_buffers = {}
    for func_name, period, token in history_self_specs:
        ring_buffers[token] = {
            "func": func_name,
            "period": period,
            "buffer": np.full(period, np.nan, dtype=np.float64),
            "pos": 0,
            "count": 0,
        }

    def ring_push(rb, value):
        rb["buffer"][rb["pos"]] = value
        rb["pos"] = (rb["pos"] + 1) % rb["period"]
        if rb["count"] < rb["period"]:
            rb["count"] += 1

    def ring_compute(rb):
        buf = rb["buffer"]
        cnt = rb["count"]
        if cnt == 0:
            return np.nan
        window = buf[:cnt] if cnt < rb["period"] else buf
        valid = window[~np.isnan(window)]
        if len(valid) == 0:
            return np.nan

        func = rb["func"]
        if func == "HISTORYAVG":
            return np.mean(valid)
        elif func == "HISTORYSUM":
            return np.sum(valid)
        elif func == "HISTORYCOUNT":
            return float(len(valid))
        elif func == "HISTORYMAX":
            return np.max(valid)
        elif func == "HISTORYMIN":
            return np.min(valid)
        elif func == "HISTORYDIFF":
            return np.max(valid) - np.min(valid)
        elif func == "HISTORYGRADIENT":
            return _scalar_gradient(valid)
        return np.nan

    # =========================================================================
    # –°–∫–∞–ª—è—Ä–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π
    # =========================================================================

    def _safe_float(v):
        if v is None:
            return np.nan
        try:
            f = float(v)
            return f
        except (TypeError, ValueError):
            return np.nan

    def _is_nan(v):
        try:
            return np.isnan(v)
        except (TypeError, ValueError):
            return True

    def WHEN(cond, t_val, f_val):
        try:
            return t_val if bool(cond) else f_val
        except (ValueError, TypeError):
            return np.nan

    def ABS(a):
        a = _safe_float(a)
        return np.abs(a) if not _is_nan(a) else np.nan

    def EXP(a):
        a = _safe_float(a)
        return np.exp(a) if not _is_nan(a) else np.nan

    def POW(a, b):
        a, b = _safe_float(a), _safe_float(b)
        if _is_nan(a) or _is_nan(b):
            return np.nan
        return np.power(a, b)

    def LOG(a):
        a = _safe_float(a)
        return np.log(a) if (not _is_nan(a) and a > 0) else np.nan

    def LOG10(a):
        a = _safe_float(a)
        return np.log10(a) if (not _is_nan(a) and a > 0) else np.nan

    def MIN(*args):
        vals = [_safe_float(a) for a in args]
        vals = [v for v in vals if not _is_nan(v)]
        return min(vals) if vals else np.nan

    def MAX(*args):
        vals = [_safe_float(a) for a in args]
        vals = [v for v in vals if not _is_nan(v)]
        return max(vals) if vals else np.nan

    def AVG(*args):
        vals = [_safe_float(a) for a in args]
        vals = [v for v in vals if not _is_nan(v)]
        return sum(vals) / len(vals) if vals else np.nan

    def MED(*args):
        vals = [_safe_float(a) for a in args]
        vals = [v for v in vals if not _is_nan(v)]
        return float(np.median(vals)) if vals else np.nan

    def ROUND(a, b=0):
        a = _safe_float(a)
        if _is_nan(a):
            return np.nan
        return round(a, int(b))

    def GETPOINT(curveName, pointX, pointY, axisToFind):
        curve_name = str(curveName)
        axis = str(axisToFind).strip().upper()

        df_tbl = TABLE_REGISTRY.get(curve_name)
        if df_tbl is None:
            return np.nan
        try:
            x, y = _get_xy_from_table(df_tbl)
        except Exception:
            return np.nan

        if axis == "Y":
            xq = _safe_float(pointX)
            if _is_nan(xq):
                return np.nan
            return float(_interp_1d(x, y, np.array([xq], dtype=np.float64))[0])

        if axis == "X":
            yq = _safe_float(pointY)
            if _is_nan(yq):
                return np.nan
            return float(_interp_1d(y, x, np.array([yq], dtype=np.float64))[0])

        return np.nan

    # =========================================================================
    # Datetime-–º–∞—Å—Å–∏–≤ –¥–ª—è HISTORYGRADIENT (–Ω—É–∂–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏)
    # =========================================================================
    if isinstance(index, pd.DatetimeIndex):
        timestamps_minutes = index.view(np.int64).astype(np.float64) / 1e9 / 60.0
    else:
        timestamps_minutes = np.arange(n, dtype=np.float64)

    # =========================================================================
    # –ì–õ–ê–í–ù–´–ô –¶–ò–ö–õ ‚Äî –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ O(n)
    # =========================================================================
    for i in range(n):
        # –ë–∞–∑–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
        env = {
            "__builtins__": {},
            "np": np,
            "WHEN": WHEN,
            "ABS": ABS,
            "EXP": EXP,
            "POW": POW,
            "LOG": LOG,
            "LOG10": LOG10,
            "MIN": MIN,
            "MAX": MAX,
            "AVG": AVG,
            "MED": MED,
            "ROUND": ROUND,
            "GETPOINT": GETPOINT,
            # PREV(self)
            "__prev_self__": result[i - 1] if i > 0 else np.nan,
        }
                # --- –ù–û–í–û–ï: X/Y –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ ---
        env["X"] = "X"
        env["Y"] = "Y"

        # --- –ù–û–í–û–ï: –∏–º–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ ---
        for tbl_name in TABLE_REGISTRY.keys():
            if tbl_name not in env:
                env[tbl_name] = tbl_name

        # –ó–Ω–∞—á–µ–Ω–∏—è –≤—Å–µ—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ —Ç–µ–∫—É—â–µ–º —à–∞–≥–µ
        for orig_name, safe in safe_name_map.items():
            env[safe] = col_arrays[orig_name][i]

        # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ PREV(other)
        for token, arr in precomputed_prev_other.items():
            env[token] = arr[i]

        # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ HISTORY*(other)
        for token, arr in precomputed_history_other.items():
            env[token] = arr[i]

        # HISTORY*(self) –∏–∑ –∫–æ–ª—å—Ü–µ–≤—ã—Ö –±—É—Ñ–µ—Ä–æ–≤
        for token, rb in ring_buffers.items():
            env[token] = ring_compute(rb)

        # –í—ã—á–∏—Å–ª—è–µ–º —Ñ–æ—Ä–º—É–ª—É
        try:
            val = eval(compiled, env)
            result[i] = float(val) if val is not None else np.nan
        except Exception:
            result[i] = np.nan

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª—å—Ü–µ–≤—ã–µ –±—É—Ñ–µ—Ä—ã HISTORY*(self) –ø–æ—Å–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        for token, rb in ring_buffers.items():
            ring_push(rb, result[i])

    return pd.Series(result, index=index, name=signal_name)


def _scalar_gradient(values: np.ndarray) -> float:
    """–ù–∞–∫–ª–æ–Ω –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–ª—è –æ–∫–Ω–∞ –∑–Ω–∞—á–µ–Ω–∏–π (—Å–∫–∞–ª—è—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è)."""
    n = len(values)
    if n < 2:
        return np.nan
    x = np.arange(n, dtype=np.float64)
    y = values.astype(np.float64)
    x_mean = x.mean()
    y_mean = y.mean()
    denom = np.sum((x - x_mean) ** 2)
    if denom == 0:
        return np.nan
    return np.sum((x - x_mean) * (y - y_mean)) / denom

def load_table_df(curve_name: str) -> pd.DataFrame:
    cache = st.session_state.tables_cache
    if curve_name in cache:
        return cache[curve_name]

    r = requests.get(f"{api_url}/api/table/file/{curve_name}")
    r.raise_for_status()
    print(BytesIO(r.content))

    df = pd.read_excel(BytesIO(r.content), engine="openpyxl")  # header=0 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    df.columns = [str(c).strip() for c in df.columns]
    df = df.dropna(axis=1, how="all")

    cache[curve_name] = df
    return df


def _precompute_gradient(series: pd.Series, period: int) -> pd.Series:
    """–ü—Ä–µ–¥–≤—ã—á–∏—Å–ª—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ (–ø–∞–∫–µ—Ç–Ω–æ)."""
    def slope(window):
        valid = window.dropna()
        if len(valid) < 2:
            return np.nan
        x = np.arange(len(valid), dtype=np.float64)
        y = valid.values.astype(np.float64)
        x_m, y_m = x.mean(), y.mean()
        d = np.sum((x - x_m) ** 2)
        if d == 0:
            return np.nan
        return np.sum((x - x_m) * (y - y_m)) / d
    return series.rolling(window=period, min_periods=2).apply(slope, raw=False)




st.set_page_config(page_title="Signal Visualizer", layout="wide")
st.title("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤")

query_params = st.query_params
session_token = query_params.get("session", None)
api_url = query_params.get("api_url", "http://localhost:8000")

signal_codes = query_params.get("signals", [])
if isinstance(signal_codes, str):
    signal_codes = [signal_codes]

CODE = ""
INITIAL_VISUALIZER_STATE = None  # –°–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
TABLES = []

if session_token:
    try:
        resp = requests.get(f"{api_url}/api/visualize/session/{session_token}")
        resp.raise_for_status()
        payload = resp.json()
        signal_codes = payload.get("signals", signal_codes)
        CODE = payload.get("code", CODE)
        TABLES = payload.get("tables", [])
        INITIAL_VISUALIZER_STATE = payload.get("visualizer_state")  # –ù–û–í–û–ï
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏: {e}")

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø SESSION STATE ===
if "signals_data" not in st.session_state:
    st.session_state.signals_data = None
if "selected_signals" not in st.session_state:
    st.session_state.selected_signals = set()
if "plot_areas" not in st.session_state:
    st.session_state.plot_areas = []
if "derived_signals" not in st.session_state:
    st.session_state.derived_signals = {}
if "code_signal_name" not in st.session_state:
    st.session_state.code_signal_name = None
if "synthetic_computed" not in st.session_state:
    st.session_state.synthetic_computed = {}
if "signal_groups" not in st.session_state:
    st.session_state.signal_groups = {"project": set(), "dependencies": set()}
if "global_cursor_time" not in st.session_state:
    st.session_state.global_cursor_time = None
# –ù–û–í–û–ï: —Ñ–ª–∞–≥ —á—Ç–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –ø—Ä–∏ rerun)
if "state_loaded" not in st.session_state:
    st.session_state.state_loaded = False
# –ù–û–í–û–ï: —Ñ–ª–∞–≥ —á—Ç–æ –µ—Å—Ç—å –Ω–µ—Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
if "has_unsaved_changes" not in st.session_state:
    st.session_state.has_unsaved_changes = False
if "tables_cache" not in st.session_state:
    st.session_state.tables_cache = {}


def mark_unsaved():
    """–ü–æ–º–µ—á–∞–µ—Ç —á—Ç–æ –µ—Å—Ç—å –Ω–µ—Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è"""
    st.session_state.has_unsaved_changes = True


def load_base_signals_data(signal_names: List[str]) -> pd.DataFrame | None:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –±–∞–∑–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∞—Ä—Ö–∏–≤–∞"""
    if not signal_names:
        return None
    
    try:
        response = requests.post(
            f"{api_url}/api/signal-data",
            json={"signal_names": signal_names, "format": "json"},
        )
        response.raise_for_status()
        result = response.json()
        
        found = result.get("found", [])
        not_found = result.get("not_found", [])
        data_dict = result.get("data", {})
        
        if not_found:
            st.warning(f"‚ö†Ô∏è –ë–∞–∑–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∞—Ä—Ö–∏–≤–µ: {', '.join(not_found)}")
        
        if not data_dict:
            return None
        
        frames = []
        for sig, records in data_dict.items():
            if not records:
                continue
            df = pd.DataFrame(records)
            if "datetime" not in df or "value" not in df:
                continue
            df["datetime"] = pd.to_datetime(df["datetime"], errors="coerce")
            df = df.dropna(subset=["datetime"])
            df = df.set_index("datetime").sort_index()
            df = df.rename(columns={"value": sig})
            frames.append(df[[sig]])
        
        if not frames:
            return None
        
        return pd.concat(frames, axis=1).sort_index()
    
    except Exception as exc:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {exc}")
        return None


def resolve_and_load_all_signals(input_signals: List[str]) -> tuple[pd.DataFrame | None, List[str], List[str]]:
    if not input_signals:
        return None, [], []
    
    try:
        with st.spinner("üîç –†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å–∏–≥–Ω–∞–ª–æ–≤..."):
            resolve_resp = requests.post(
                f"{api_url}/api/resolve-signals",
                json={"signals": input_signals}
            )
            resolve_resp.raise_for_status()
            resolve_data = resolve_resp.json()
        
        base_signals = resolve_data.get("base_signals", [])
        synthetic_signals = resolve_data.get("synthetic_signals", {})
        computation_order = resolve_data.get("computation_order", [])
        
        project_signals = set(input_signals)
        dependency_signals = set()
        for syn_name, syn_data in synthetic_signals.items():
            if syn_name not in project_signals:
                dependency_signals.add(syn_name)
            for dep in syn_data.get("dependencies", []):
                if dep not in project_signals:
                    dependency_signals.add(dep)
        
        for bs in base_signals:
            if bs not in project_signals:
                dependency_signals.add(bs)
        
        st.session_state.signal_groups = {
            "project": project_signals,
            "dependencies": dependency_signals
        }
        
        st.info(f"üìä –°–∏–≥–Ω–∞–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞: {len(project_signals)} | –ò–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {len(dependency_signals)}")
        
        if synthetic_signals:
            with st.expander("üîó –ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"):
                for syn_name in computation_order:
                    deps = synthetic_signals[syn_name].get("dependencies", [])
                    marker = "üìå" if syn_name in project_signals else "üîó"
                    st.text(f"  {marker} {syn_name} ‚Üê {deps}")
        
        df_all = None
        found_signals = []
        not_found_signals = []
        
        if base_signals:
            with st.spinner(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º {len(base_signals)} –±–∞–∑–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤..."):
                df_all = load_base_signals_data(base_signals)
                if df_all is not None:
                    found_signals = list(df_all.columns)
                    not_found_signals = [s for s in base_signals if s not in df_all.columns]

        
        
        if df_all is None:
            df_all = pd.DataFrame()
        
                # === –î–ï–¢–ï–ö–¶–ò–Ø –°–ê–ú–û–°–°–´–õ–ê–Æ–©–ò–•–°–Ø –°–ò–ì–ù–ê–õ–û–í ===
        self_referential_signals = set()
        for name, data in synthetic_signals.items():
            if name in data.get("dependencies", []):  # –ü—Ä—è–º–∞—è —Å–∞–º–æ—Å—Å—ã–ª–∫–∞
                self_referential_signals.add(name)
        
        batch_order = [s for s in computation_order if s not in self_referential_signals]
        streaming_order = [s for s in computation_order if s in self_referential_signals]

        # === –í–´–ß–ò–°–õ–ï–ù–ò–ï –ü–ê–ö–ï–¢–ù–´–• –°–ò–ì–ù–ê–õ–û–í (–±–µ–∑ —Å–∞–º–æ—Å—Å—ã–ª–æ–∫) ===
        if batch_order:
            with st.spinner(f"‚öôÔ∏è –í—ã—á–∏—Å–ª—è–µ–º {len(batch_order)} –ø–∞–∫–µ—Ç–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤..."):
                progress_bar = st.progress(0)
                for idx, syn_name in enumerate(batch_order):
                    syn_data = synthetic_signals[syn_name]
                    formula = syn_data.get("formula", "")
                    if not formula or df_all.empty:
                        continue
                    try:
                        syn_series = compute_code_signal(
                            formula, df_all,
                            warn_callback=lambda msg, name=syn_name: st.warning(f"[{name}] {msg}", icon="‚ö†Ô∏è")
                        )
                        syn_series.name = syn_name
                        df_all[syn_name] = syn_series
                        found_signals.append(syn_name)
                        st.session_state.synthetic_computed[syn_name] = formula
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ '{syn_name}': {e}")
                        not_found_signals.append(syn_name)
                    progress_bar.progress((idx + 1) / len(batch_order))
                progress_bar.empty()

        # === –í–´–ß–ò–°–õ–ï–ù–ò–ï –ü–û–¢–û–ö–û–í–´–• –°–ò–ì–ù–ê–õ–û–í (—Å —Å–∞–º–æ—Å—Å—ã–ª–∫–æ–π) ===
        if streaming_order:
            with st.spinner(f"üåÄ –í—ã—á–∏—Å–ª—è–µ–º {len(streaming_order)} –ø–æ—Ç–æ–∫–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤..."):
                progress_bar = st.progress(0)
                for idx, syn_name in enumerate(streaming_order):
                    syn_data = synthetic_signals[syn_name]
                    formula = syn_data.get("formula", "")
                    if not formula or df_all.empty:
                        not_found_signals.append(syn_name)
                        progress_bar.progress((idx + 1) / len(streaming_order))
                        continue
                    try:
                        #streaming_series = compute_streaming_signal_streaming_forward(
                        #    formula=formula,
                        #    df_base=df_all,
                        #    signal_name=syn_name,
                        #    )
                        streaming_series = compute_streaming_signal(
                            formula=formula,
                            df_base=df_all,
                            signal_name=syn_name,
                        )
                        df_all[syn_name] = streaming_series
                        found_signals.append(syn_name)
                        st.session_state.synthetic_computed[syn_name] = formula
                        st.info(f"‚úÖ –ü–æ—Ç–æ–∫–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª '{syn_name}' –≤—ã—á–∏—Å–ª–µ–Ω")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞ '{syn_name}': {e}")
                        not_found_signals.append(syn_name)
                    progress_bar.progress((idx + 1) / len(streaming_order))
                progress_bar.empty()
        
        return df_all if not df_all.empty else None, found_signals, not_found_signals
    
    except requests.exceptions.HTTPError as http_err:
        error_detail = ""
        try:
            error_detail = http_err.response.json().get("detail", "")
        except:
            pass
        st.error(f"‚ùå –û—à–∏–±–∫–∞ API: {error_detail or http_err}")
        return None, [], []
    except Exception as exc:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {exc}")
        import traceback
        st.code(traceback.format_exc())
        return None, [], []


# ========== –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ==========
if signal_codes and st.session_state.signals_data is None:
    df_base, found_codes, not_found_codes = resolve_and_load_all_signals(signal_codes)
    st.session_state.signals_data = df_base
    
    if found_codes:
        st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(found_codes)}")
    if not_found_codes:
        st.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã: {', '.join(not_found_codes)}")

if TABLES:
    for t in TABLES:
        try:
            load_table_df(t)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ '{t}' –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {e}")

    # –ü–µ—Ä–µ–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã –≤ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å (code_signal.py)
    register_tables(st.session_state.tables_cache)
else:
    print('NO tables')
    register_tables({})


def get_all_signals_df(exclude: set[str] | None = None):
    exclude = exclude or set()
    base = st.session_state.signals_data
    derived = st.session_state.derived_signals

    dfs = []
    if base is not None:
        dfs.append(base)
    for name, ddf in derived.items():
        if name in exclude:
            continue
        dfs.append(ddf)

    if not dfs:
        return None
    return pd.concat(dfs, axis=1).sort_index()


def compute_stats_numeric(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()

    numeric = df.apply(sanitize_numeric_column)
    valid_cols = [col for col in numeric.columns if numeric[col].count() > 0]
    if not valid_cols:
        return pd.DataFrame()

    numeric = numeric[valid_cols]
    stats = pd.DataFrame(index=numeric.columns)
    stats["count"] = numeric.count()
    stats["min"] = numeric.min()
    stats["max"] = numeric.max()
    stats["mean"] = numeric.mean()
    stats["std"] = numeric.std()
    stats["median"] = numeric.median()

    starts, ends = [], []
    for col in numeric.columns:
        series = numeric[col].dropna()
        starts.append(series.index.min() if not series.empty else pd.NaT)
        ends.append(series.index.max() if not series.empty else pd.NaT)

    stats["start"] = starts
    stats["end"] = ends
    return stats


def make_unique_name(base_name: str) -> str:
    existing = set()
    if st.session_state.signals_data is not None:
        existing |= set(st.session_state.signals_data.columns)
    existing |= set(st.session_state.derived_signals.keys())
    if base_name not in existing:
        return base_name
    idx = 2
    while f"{base_name}_{idx}" in existing:
        idx += 1
    return f"{base_name}_{idx}"


# --- —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Å–∏–≥–Ω–∞–ª –∏–∑ CODE ---
code_signal_name = st.session_state.code_signal_name
df_for_code = get_all_signals_df(exclude={code_signal_name} if code_signal_name else None)
code_key = (session_token, CODE)

already_have_series = (
    st.session_state.code_signal_name is not None
    and st.session_state.code_signal_name in st.session_state.derived_signals
)

if CODE and df_for_code is not None:
    need_recalc = (st.session_state.get("code_key") != code_key) or (not already_have_series)

    if need_recalc:
        try:
            synthetic_series = compute_code_signal(
                CODE,
                df_for_code,
                warn_callback=lambda msg: st.warning(msg, icon="‚ö†Ô∏è"),
            )
            target_name = code_signal_name or make_unique_name("CODE_RESULT")
            synthetic_series.name = target_name

            st.session_state.derived_signals[target_name] = pd.DataFrame({target_name: synthetic_series})
            st.session_state.code_signal_name = target_name
            st.session_state.selected_signals.add(target_name)

            st.session_state.code_key = code_key
            st.success(f"–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Å–∏–≥–Ω–∞–ª –æ–±–Ω–æ–≤–ª—ë–Ω: {target_name}")
        except Exception as exc:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å CODE: {exc}")

elif not CODE:
    if code_signal_name:
        st.session_state.derived_signals.pop(code_signal_name, None)
        st.session_state.selected_signals.discard(code_signal_name)
        st.session_state.code_signal_name = None
    st.session_state.code_key = None


# === –ó–ê–ì–†–£–ó–ö–ê –°–û–•–†–ê–ù–Å–ù–ù–û–ì–û –°–û–°–¢–û–Ø–ù–ò–Ø (–æ–¥–∏–Ω —Ä–∞–∑) ===
df_all_signals = get_all_signals_df()

if not st.session_state.state_loaded and INITIAL_VISUALIZER_STATE and df_all_signals is not None:
    available_signals = set(df_all_signals.columns.tolist())
    
    loaded_selected, loaded_areas, load_warnings = load_visualizer_state(
        INITIAL_VISUALIZER_STATE,
        available_signals
    )
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    if loaded_selected:
        st.session_state.selected_signals = loaded_selected
    if loaded_areas:
        st.session_state.plot_areas = loaded_areas
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
    for warn in load_warnings:
        st.warning(f"‚ö†Ô∏è {warn}")
    
    if loaded_selected or loaded_areas:
        st.info("üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞")
    
    st.session_state.state_loaded = True
    st.session_state.has_unsaved_changes = False


# === –§–£–ù–ö–¶–ò–Ø –°–û–•–†–ê–ù–ï–ù–ò–Ø –°–û–°–¢–û–Ø–ù–ò–Ø ===
def save_current_state():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä"""
    if not session_token:
        st.error("–ù–µ—Ç —Ç–æ–∫–µ–Ω–∞ —Å–µ—Å—Å–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return False
    
    state = create_visualizer_state(
        st.session_state.selected_signals,
        st.session_state.plot_areas
    )
    
    try:
        resp = requests.post(
            f"{api_url}/api/visualize/save-state",
            json={
                "session_token": session_token,
                "state": state
            }
        )
        resp.raise_for_status()
        result = resp.json()
        
        if result.get("success"):
            st.session_state.has_unsaved_changes = False
            return True
        else:
            st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {result.get('message')}")
            return False
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
        return False


# === SIDEBAR ===
with st.sidebar:
    st.header("–í—ã–±–æ—Ä —Å–∏–≥–Ω–∞–ª–æ–≤")
    
    # –ù–û–í–û–ï: –ö–Ω–æ–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if session_token:
        save_col1, save_col2 = st.columns([2, 1])
        with save_col1:
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ", use_container_width=True):
                if save_current_state():
                    st.success("‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")
                    st.info("üí° –¢–µ–ø–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ")
        with save_col2:
            if st.session_state.has_unsaved_changes:
                st.markdown("üî¥ *–ò–∑–º–µ–Ω–µ–Ω–∏—è*")
            else:
                st.markdown("üü¢ *–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ*")
        st.divider()

    if df_all_signals is not None:
        available_signals = df_all_signals.columns.tolist()
        
        signal_groups = st.session_state.get("signal_groups", {
            "project": set(available_signals),
            "dependencies": set()
        })
        
        project_signals = [s for s in available_signals if s in signal_groups.get("project", set())]
        dependency_signals = [s for s in available_signals if s in signal_groups.get("dependencies", set())]
        
        if project_signals:
            st.subheader("üìå –°–∏–≥–Ω–∞–ª—ã –ø—Ä–æ–µ–∫—Ç–∞")
            for signal in project_signals:
                is_synthetic = signal in st.session_state.get("synthetic_computed", {})
                label = f"‚öôÔ∏è {signal}" if is_synthetic else signal
                
                checked = st.checkbox(
                    label,
                    value=(signal in st.session_state.selected_signals),
                    key=f"proj_{signal}"
                )
                if checked and signal not in st.session_state.selected_signals:
                    st.session_state.selected_signals.add(signal)
                    mark_unsaved()
                elif not checked and signal in st.session_state.selected_signals:
                    st.session_state.selected_signals.discard(signal)
                    mark_unsaved()
        
        if dependency_signals:
            st.divider()
            with st.expander(f"üîó –ò–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π ({len(dependency_signals)})", expanded=False):
                for signal in dependency_signals:
                    is_synthetic = signal in st.session_state.get("synthetic_computed", {})
                    label = f"‚öôÔ∏è {signal}" if is_synthetic else signal
                    
                    checked = st.checkbox(
                        label,
                        value=(signal in st.session_state.selected_signals),
                        key=f"dep_{signal}"
                    )
                    if checked and signal not in st.session_state.selected_signals:
                        st.session_state.selected_signals.add(signal)
                        mark_unsaved()
                    elif not checked and signal in st.session_state.selected_signals:
                        st.session_state.selected_signals.discard(signal)
                        mark_unsaved()
        
        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚úÖ –í—Å–µ –ø—Ä–æ–µ–∫—Ç–∞"):
                st.session_state.selected_signals.update(project_signals)
                mark_unsaved()
                st.rerun()
        with col2:
            if st.button("‚ùå –°–Ω—è—Ç—å –≤—Å–µ"):
                st.session_state.selected_signals.clear()
                mark_unsaved()
                st.rerun()

        st.divider()
        st.subheader("–°–æ–∑–¥–∞—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª")

        base_df = st.session_state.signals_data
        if base_df is not None and not base_df.empty:
            base_choice = st.selectbox("–ò—Å—Ö–æ–¥–Ω—ã–π —Å–∏–≥–Ω–∞–ª", base_df.columns)
            series = base_df[base_choice].dropna()
            if not series.empty:
                col1, col2 = st.columns(2)
                with col1:
                    start_date = st.date_input(
                        "–ù–∞—á–∞–ª–æ",
                        value=series.index.min().date(),
                    )
                with col2:
                    end_date = st.date_input(
                        "–ö–æ–Ω–µ—Ü",
                        value=series.index.max().date(),
                    )

                start_ts = pd.Timestamp(start_date)
                end_ts = pd.Timestamp(end_date) + pd.Timedelta(days=1) - pd.Timedelta(
                    microseconds=1
                )

                default_name = f"{base_choice}__{start_ts.date()}_{end_ts.date()}"
                new_name = st.text_input("–ò–º—è –Ω–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞", value=default_name)

                col3, col4 = st.columns(2)
                if col3.button("–°–æ–∑–¥–∞—Ç—å"):
                    name_unique = make_unique_name(new_name.strip())
                    cut_series = series[(series.index >= start_ts) & (series.index <= end_ts)]
                    if cut_series.empty:
                        st.warning("–í –≤—ã–±—Ä–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –Ω–µ—Ç —Ç–æ—á–µ–∫.")
                    else:
                        st.session_state.derived_signals[name_unique] = pd.DataFrame(
                            {name_unique: cut_series}
                        )
                        st.success(f"–°–æ–∑–¥–∞–Ω –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª: {name_unique}")
                        st.rerun()
                if col4.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ"):
                    st.session_state.derived_signals = {
                        k: v
                        for k, v in st.session_state.derived_signals.items()
                        if k == st.session_state.code_signal_name
                    }
                    st.session_state.selected_signals = {
                        sig
                        for sig in st.session_state.selected_signals
                        if (st.session_state.signals_data is not None and sig in st.session_state.signals_data.columns)
                        or sig == st.session_state.code_signal_name
                    }
                    st.rerun()

        if st.session_state.derived_signals:
            st.subheader("–£–¥–∞–ª–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π/—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Å–∏–≥–Ω–∞–ª")
            derived_names = [name for name in st.session_state.derived_signals.keys()]
            delete_candidate = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ", ["‚Äî"] + derived_names)
            if st.button("–£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π") and delete_candidate != "‚Äî":
                st.session_state.derived_signals.pop(delete_candidate, None)
                st.session_state.selected_signals.discard(delete_candidate)
                if delete_candidate == st.session_state.code_signal_name:
                    st.session_state.code_signal_name = None
                st.rerun()

        st.divider()
        st.subheader("–û–±–ª–∞—Å—Ç–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è")
        col_a, col_b = st.columns(2)
        if col_a.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫"):
            new_id = max([area.get("id", 0) for area in st.session_state.plot_areas] + [0]) + 1
            st.session_state.plot_areas.append({
                "id": new_id, 
                "signals": [], 
                "shapes": [], 
                "cursor_time": None,
                "x_range": None,
                "y_range": None
            })
            mark_unsaved()
            st.rerun()
        if col_b.button("‚ùå –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ"):
            st.session_state.plot_areas = []
            st.session_state.selected_signals = set()
            st.session_state.global_cursor_time = None
            mark_unsaved()
            st.rerun()
    else:
        st.info("üì• –î–∞–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")


def find_nearest_index_in_range(valid_index, target_time, x_start, x_end):
    """–ù–∞—Ö–æ–¥–∏—Ç –±–ª–∏–∂–∞–π—à–∏–π –∏–Ω–¥–µ–∫—Å –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ"""
    mask = (valid_index >= x_start) & (valid_index <= x_end)
    filtered_index = valid_index[mask]
    
    if len(filtered_index) == 0:
        return 0, valid_index[0] if len(valid_index) > 0 else None
    
    if target_time is None:
        return 0, filtered_index[0]
    
    diffs = abs((filtered_index - pd.to_datetime(target_time)).total_seconds())
    min_pos = diffs.argmin()
    return min_pos, filtered_index[min_pos]


# === –û–°–ù–û–í–ù–ê–Ø –û–ë–õ–ê–°–¢–¨ –ì–†–ê–§–ò–ö–û–í ===
if df_all_signals is not None and st.session_state.selected_signals:
    if not st.session_state.plot_areas:
        st.session_state.plot_areas.append({
            "id": 1, 
            "signals": list(st.session_state.selected_signals), 
            "shapes": [], 
            "cursor_time": None,
            "x_range": None,
            "y_range": None
        })

    for i, plot_area in enumerate(st.session_state.plot_areas):
        with st.container():
            col1, col2 = st.columns([3, 1])
            with col1:
                st.subheader(f"–ì—Ä–∞—Ñ–∏–∫ #{plot_area['id']}")
            with col2:
                if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"remove_area_{i}"):
                    st.session_state.plot_areas.pop(i)
                    mark_unsaved()
                    st.rerun()

            selected = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Å–∏–≥–Ω–∞–ª(—ã):",
                list(st.session_state.selected_signals),
                default=plot_area.get("signals", []),
                key=f"signals_sel_{i}",
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ —Å–∏–≥–Ω–∞–ª—ã
            if set(selected) != set(plot_area.get("signals", [])):
                mark_unsaved()
            st.session_state.plot_areas[i]["signals"] = selected

            if selected:
                df_plot = df_all_signals[selected].copy()
                df_plot_num = df_plot.apply(sanitize_numeric_column)

                valid_index = df_plot_num.dropna(how="all").index
                if len(valid_index) == 0:
                    st.warning("–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤.")
                else:
                    full_x_min = valid_index.min()
                    full_x_max = valid_index.max()
                    
                    y_data = df_plot_num.values.flatten()
                    y_data = y_data[~np.isnan(y_data)]
                    full_y_min = float(y_data.min()) if len(y_data) > 0 else 0.0
                    full_y_max = float(y_data.max()) if len(y_data) > 0 else 1.0
                    
                    y_padding = (full_y_max - full_y_min) * 0.05
                    full_y_min -= y_padding
                    full_y_max += y_padding

                    if plot_area.get('x_range') is None:
                        plot_area['x_range'] = [full_x_min, full_x_max]
                    
                    if plot_area.get('y_range') is None:
                        plot_area['y_range'] = [full_y_min, full_y_max]

                    x_start_ts, x_end_ts = plot_area['x_range']
                    mask_visible = (valid_index >= x_start_ts) & (valid_index <= x_end_ts)
                    visible_index = valid_index[mask_visible]
                    
                    if len(visible_index) == 0:
                        st.warning("–í –≤—ã–±—Ä–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ X –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
                    else:
                        if plot_area.get('cursor_time') is None:
                            plot_area['cursor_time'] = visible_index[len(visible_index) // 2]
                        
                        cursor_time = plot_area['cursor_time']
                        if cursor_time < x_start_ts or cursor_time > x_end_ts:
                            cursor_time = visible_index[len(visible_index) // 2]
                            plot_area['cursor_time'] = cursor_time
                        
                        cursor_pos, _ = find_nearest_index_in_range(
                            visible_index, cursor_time, x_start_ts, x_end_ts
                        )
                        
                        if st.session_state.global_cursor_time is not None:
                            global_cursor = st.session_state.global_cursor_time
                            if x_start_ts <= global_cursor <= x_end_ts:
                                cursor_pos, cursor_time = find_nearest_index_in_range(
                                    visible_index, global_cursor, x_start_ts, x_end_ts
                                )
                                plot_area['cursor_time'] = cursor_time
                        
                        ts_idx = st.slider(
                            "üìç –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è (–≤ –≤–∏–¥–∏–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ)",
                            min_value=0,
                            max_value=len(visible_index) - 1,
                            value=min(cursor_pos, len(visible_index) - 1),
                            key=f"vline_slider_{i}",
                            help="–°–ª–∞–π–¥–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ —Ä–∞–º–∫–∞—Ö —Ç–µ–∫—É—â–µ–≥–æ –≤–∏–¥–∏–º–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ X"
                        )
                        
                        ts = visible_index[ts_idx]
                        plot_area['cursor_time'] = ts
                        
                        col_pos, col_sync = st.columns([3, 1])
                        with col_pos:
                            st.markdown(f"**üìÖ –ü–æ–∑–∏—Ü–∏—è –ª–∏–Ω–∏–∏:** `{ts.strftime('%Y-%m-%d %H:%M:%S')}`")
                        with col_sync:
                            if st.button("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ", key=f"sync_{i}"):
                                st.session_state.global_cursor_time = ts
                                for pa in st.session_state.plot_areas:
                                    pa['cursor_time'] = ts
                                st.rerun()

                        fig = px.line(
                            df_plot_num,
                            x=df_plot_num.index,
                            y=selected,
                            title=f"–ì—Ä–∞—Ñ–∏–∫ #{plot_area['id']}",
                            render_mode="webgl"
                        )
                        
                        fig.add_vline(x=ts, line_width=2, line_dash="dash", line_color="red")
                        
                        shapes = plot_area.get('shapes', [])
                        for shape in shapes:
                            if shape['type'] == 'vline':
                                fig.add_vline(x=shape['x'], line_dash=shape['dash'], line_color=shape['color'], line_width=1)
                            elif shape['type'] == 'hline':
                                fig.add_hline(y=shape['y'], line_dash=shape['dash'], line_color=shape['color'], line_width=1)
                        
                        fig.update_layout(
                            uirevision=f"plot_area_{plot_area['id']}",
                            height=600,
                            legend_title_text="–°–∏–≥–Ω–∞–ª—ã",
                            xaxis_title="–í—Ä–µ–º—è",
                            yaxis_title="–ó–Ω–∞—á–µ–Ω–∏–µ",
                            margin=dict(l=20, r=20, t=40, b=20),
                            xaxis=dict(
                                range=[x_start_ts, x_end_ts],
                                rangeslider=dict(
                                    visible=True,
                                    thickness=0.08,
                                    bgcolor='#e0e0e0',
                                    range=[full_x_min, full_x_max]
                                )
                            ),
                            yaxis=dict(
                                range=plot_area['y_range'],
                                fixedrange=False
                            )
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)

                        with st.expander(f"üìç –î–æ–±–∞–≤–∏—Ç—å –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ #{plot_area['id']}"):
                            col_x, col_y = st.columns(2)
                            with col_x:
                                st.markdown("**–í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è (X)**")
                                x_date = st.date_input("–î–∞—Ç–∞", value=ts.date(), key=f"x_date_{i}")
                                x_time = st.time_input("–í—Ä–µ–º—è", value=ts.time(), key=f"x_time_{i}")
                                x_full = pd.Timestamp.combine(x_date, x_time)
                                if st.button("–î–æ–±–∞–≤–∏—Ç—å V-line", key=f"add_vline_{i}"):
                                    shapes.append({
                                        'type': 'vline',
                                        'x': x_full,
                                        'dash': 'dot',
                                        'color': 'blue'
                                    })
                                    plot_area['shapes'] = shapes
                                    mark_unsaved()
                                    st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –ª–∏–Ω–∏—è –Ω–∞ {x_full}")
                                    st.rerun()
                            
                            with col_y:
                                st.markdown("**–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è (Y)**")
                                y_value = st.number_input("–ó–Ω–∞—á–µ–Ω–∏–µ Y", value=0.0, key=f"y_val_{i}")
                                if st.button("–î–æ–±–∞–≤–∏—Ç—å H-line", key=f"add_hline_{i}"):
                                    shapes.append({
                                        'type': 'hline',
                                        'y': y_value,
                                        'dash': 'dash',
                                        'color': 'green'
                                    })
                                    plot_area['shapes'] = shapes
                                    mark_unsaved()
                                    st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –ª–∏–Ω–∏—è –Ω–∞ Y={y_value}")
                                    st.rerun()
                            
                            if shapes:
                                st.markdown("**–¢–µ–∫—É—â–∏–µ –º–∞—Ä–∫–µ—Ä—ã:**")
                                for j, s in enumerate(shapes):
                                    if s['type'] == 'vline':
                                        st.text(f"  V-line: {s['x']} ({s['color']})")
                                    else:
                                        st.text(f"  H-line: Y={s['y']} ({s['color']})")
                                if st.button(f"üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –º–∞—Ä–∫–µ—Ä—ã", key=f"clear_shapes_{i}"):
                                    plot_area['shapes'] = []
                                    mark_unsaved()
                                    st.rerun()

                        nearest = df_plot_num.reindex(df_plot_num.index.union([ts])).sort_index()
                        nearest = nearest.ffill().loc[ts]

                        st.markdown("**üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**")
                        stats_df = compute_stats_numeric(df_plot)
                        if stats_df.empty:
                            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.")
                        else:
                            stats_view = stats_df.copy()
                            stats_view["value"] = nearest.reindex(stats_view.index)
                            stats_view["start"] = pd.to_datetime(stats_view["start"], errors="coerce").dt.strftime("%Y-%m-%d %H:%M:%S")
                            stats_view["end"] = pd.to_datetime(stats_view["end"], errors="coerce").dt.strftime("%Y-%m-%d %H:%M:%S")
                            st.dataframe(
                                stats_view.style.format(
                                    {
                                        "count": "{:.0f}",
                                        "min": "{:.6g}",
                                        "max": "{:.6g}",
                                        "mean": "{:.6g}",
                                        "std": "{:.6g}",
                                        "median": "{:.6g}",
                                        "value": "{:.6g}",
                                    },
                                    na_rep="",
                                ),
                                use_container_width=True,
                            )
            else:
                st.info("–í—ã–±–µ—Ä–∏—Ç–µ —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        st.divider()

elif df_all_signals is None:
    st.info("üì• –î–∞–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
else:
    st.info("üëà –í—ã–±–µ—Ä–∏—Ç–µ —Å–∏–≥–Ω–∞–ª—ã —Å–ª–µ–≤–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.")

if df_all_signals is not None:
    with st.expander("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö"):
        # === –û–ë–õ–ê–ö–û –¢–û–ß–ï–ö X‚ÄìY + –ê–ü–ü–†–û–ö–°–ò–ú–ê–¶–ò–Ø (–≤—Å–µ–≥–¥–∞ –≤–Ω–∏–∑—É) ===
        # === –û–ë–õ–ê–ö–û –¢–û–ß–ï–ö X‚ÄìY + –ê–ü–ü–†–û–ö–°–ò–ú–ê–¶–ò–Ø (–≤—Å–µ–≥–¥–∞ –≤–Ω–∏–∑—É) ===
        if df_all_signals is not None:
            # –î–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ –æ—Ç–º–µ—á–µ–Ω–Ω—ã–µ –≥–∞–ª–æ—á–∫–∞–º–∏ —Å–∏–≥–Ω–∞–ª—ã + CODE_RESULT (–µ—Å–ª–∏ –µ—Å—Ç—å)
            available_cols = df_all_signals.columns.tolist()
            selected_set = st.session_state.get("selected_signals", set())
            available_signals = [c for c in available_cols if c in selected_set]

            code_sig = st.session_state.get("code_signal_name")
            if code_sig and code_sig in available_cols and code_sig not in available_signals:
                available_signals.append(code_sig)

            st.divider()
            st.subheader("üî∑ –û–±–ª–∞–∫–æ —Ç–æ—á–µ–∫ X‚ÄìY + –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è")

            # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º –¥–≤–∞ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ—Å–µ–π
            if len(available_signals) < 2:
                st.info("–û—Ç–º–µ—Ç—å—Ç–µ –º–∏–Ω–∏–º—É–º –¥–≤–∞ —Å–∏–≥–Ω–∞–ª–∞ —Å–ª–µ–≤–∞ (–≤–∫–ª—é—á–∞—è –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ CODE_RESULT), —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å X –∏ Y.")
            else:
                # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: X ‚Äî –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π; Y ‚Äî CODE_RESULT, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –≤—Ç–æ—Ä–æ–π
                default_x_idx = 0
                default_y_idx = 1
                if code_sig and code_sig in available_signals:
                    default_y_idx = available_signals.index(code_sig)

                col_sel = st.columns(3)
                with col_sel[0]:
                    x_sig = st.selectbox(
                        "–û—Å—å X",
                        available_signals,
                        index=min(default_x_idx, len(available_signals) - 1),
                        key="xy_x_sig"
                    )
                with col_sel[1]:
                    y_sig = st.selectbox(
                        "–û—Å—å Y",
                        available_signals,
                        index=min(default_y_idx, len(available_signals) - 1),
                        key="xy_y_sig"
                    )
                with col_sel[2]:
                    max_points = st.number_input(
                        "–ú–∞–∫—Å. —Ç–æ—á–µ–∫ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ",
                        min_value=100,
                        max_value=500_000,
                        value=50_000,
                        step=100,
                        help="–î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö",
                        key="xy_max_points"
                    )

                # –ë–∞–∑–æ–≤—ã–µ —Å–µ—Ä–∏–∏ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã/–º–∞–∫—Å–∏–º—É–º—ã
                x_series = sanitize_numeric_column(df_all_signals[x_sig])
                y_series = sanitize_numeric_column(df_all_signals[y_sig])

                x_min_default = float(x_series.dropna().min()) if x_series.dropna().size > 0 else 0.0
                x_max_default = float(x_series.dropna().max()) if x_series.dropna().size > 0 else 1.0
                y_min_default = float(y_series.dropna().min()) if y_series.dropna().size > 0 else 0.0
                y_max_default = float(y_series.dropna().max()) if y_series.dropna().size > 0 else 1.0

                # UI —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (–∫–∞–∂–¥–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞)
                st.markdown("**–§–∏–ª—å—Ç—Ä –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**")
                col_f = st.columns(2)

                with col_f[0]:
                    st.markdown(f"**–§–∏–ª—å—Ç—Ä –ø–æ X: {x_sig}**")
                    x_min_en = st.checkbox("–ó–∞–¥–∞—Ç—å –º–∏–Ω–∏–º—É–º X", value=False, key="xy_x_min_en")
                    x_min_val = st.number_input("–ú–∏–Ω–∏–º—É–º X", value=x_min_default, key="xy_x_min", disabled=not x_min_en)
                    x_max_en = st.checkbox("–ó–∞–¥–∞—Ç—å –º–∞–∫—Å–∏–º—É–º X", value=False, key="xy_x_max_en")
                    x_max_val = st.number_input("–ú–∞–∫—Å–∏–º—É–º X", value=x_max_default, key="xy_x_max", disabled=not x_max_en)

                with col_f[1]:
                    st.markdown(f"**–§–∏–ª—å—Ç—Ä –ø–æ Y: {y_sig}**")
                    y_min_en = st.checkbox("–ó–∞–¥–∞—Ç—å –º–∏–Ω–∏–º—É–º Y", value=False, key="xy_y_min_en")
                    y_min_val = st.number_input("–ú–∏–Ω–∏–º—É–º Y", value=y_min_default, key="xy_y_min", disabled=not y_min_en)
                    y_max_en = st.checkbox("–ó–∞–¥–∞—Ç—å –º–∞–∫—Å–∏–º—É–º Y", value=False, key="xy_y_max_en")
                    y_max_val = st.number_input("–ú–∞–∫—Å–∏–º—É–º Y", value=y_max_default, key="xy_y_max", disabled=not y_max_en)

                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä—ã (X(t), Y(t)) –ø–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º –º–µ—Ç–∫–∞–º –≤—Ä–µ–º–µ–Ω–∏, —Å—Ä–∞–∑—É —Å–±—Ä–∞—Å—ã–≤–∞–µ–º NaN
                xy_df = pd.DataFrame({x_sig: x_series, y_sig: y_series}).dropna()

                original_count = len(xy_df)

                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã: –∫–∞–∂–¥–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
                if x_min_en:
                    xy_df = xy_df[xy_df[x_sig] >= x_min_val]
                if x_max_en:
                    xy_df = xy_df[xy_df[x_sig] <= x_max_val]
                if y_min_en:
                    xy_df = xy_df[xy_df[y_sig] >= y_min_val]
                if y_max_en:
                    xy_df = xy_df[xy_df[y_sig] <= y_max_val]

                filtered_count = len(xy_df)

                # –ü–æ–¥–≤—ã–±–æ—Ä–∫–∞ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ‚Äî –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–µ–Ω–¥–µ—Ä–∞
                if filtered_count > max_points:
                    step = max(1, filtered_count // max_points)
                    xy_df = xy_df.iloc[::step, :]
                    # –ø–æ—Å–ª–µ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –Ω–µ –º–µ–Ω—è–µ–º filtered_count, –æ–Ω –æ—Ç—Ä–∞–∂–∞–µ—Ç –æ–±—ä—ë–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏

                if xy_df.empty:
                    st.warning("–ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
                else:
                    x_vals = xy_df[x_sig].to_numpy(dtype=np.float64)
                    y_vals = xy_df[y_sig].to_numpy(dtype=np.float64)

                    st.caption(f"–¢–æ—á–µ–∫ –≤—Å–µ–≥–æ: {original_count} | –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞: {filtered_count} | –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–æ: {len(xy_df)}")

                    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏
                    fit_type = st.selectbox(
                        "–¢–∏–ø –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏",
                        ["–ë–µ–∑ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏", "–õ–∏–Ω–µ–π–Ω–∞—è (y = a + b¬∑X)", "–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Å—Ç–µ–ø–µ–Ω—å N", "–°—Ç–µ–ø–µ–Ω–Ω–∞—è (y = a¬∑X^p)"],
                        key="xy_fit_type"
                    )

                    poly_degree = None
                    if "–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è" in fit_type:
                        poly_degree = st.slider(
                            "–°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞ (N)",
                            min_value=2, max_value=8, value=2, step=1,
                            key="xy_poly_deg"
                        )

                    # –û–±–ª–∞–∫–æ —Ç–æ—á–µ–∫
                    fig_scatter = px.scatter(
                        xy_df, x=x_sig, y=y_sig,
                        title=f"–û–±–ª–∞–∫–æ —Ç–æ—á–µ–∫: {x_sig} ‚Üí {y_sig}",
                        render_mode="webgl",
                        opacity=0.75
                    )

                    # –î–∏–∞–ø–∞–∑–æ–Ω X –¥–ª—è –∫—Ä–∏–≤–æ–π
                    x_min = float(np.nanmin(x_vals))
                    x_max = float(np.nanmax(x_vals))
                    x_grid = np.linspace(x_min, x_max, 500)

                    info_lines = []
                    if fit_type.startswith("–õ–∏–Ω–µ–π–Ω–∞—è"):
                        fit = fit_linear(x_vals, y_vals)
                        a, b, r2 = fit["a"], fit["b"], fit["r2"]
                        y_line = a + b * x_grid
                        fig_scatter.add_trace(go.Scatter(x=x_grid, y=y_line, mode="lines", name="–õ–∏–Ω–µ–π–Ω–∞—è –∞–ø–ø—Ä.", line=dict(color="red", width=2)))
                        info_lines.append(f"–ú–æ–¥–µ–ª—å: {y_sig} = {a:.6g} + {b:.6g}¬∑{x_sig}")
                        info_lines.append(f"R¬≤ = {r2:.4f}" if not np.isnan(r2) else "R¬≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

                    elif fit_type.startswith("–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è"):
                        fit = fit_polynomial(x_vals, y_vals, degree=poly_degree or 2)
                        coeffs, r2 = fit["coeffs"], fit["r2"]
                        if coeffs is None:
                            info_lines.append("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏ –ø–æ–ª–∏–Ω–æ–º–∞.")
                        else:
                            y_line = np.polyval(coeffs, x_grid)
                            fig_scatter.add_trace(go.Scatter(x=x_grid, y=y_line, mode="lines", name=f"–ü–æ–ª–∏–Ω–æ–º N={poly_degree}", line=dict(color="orange", width=2)))
                            info_lines.append(_format_poly_equation(coeffs, x_sig, y_sig))
                            info_lines.append(f"R¬≤ = {r2:.4f}" if not np.isnan(r2) else "R¬≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

                    elif fit_type.startswith("–°—Ç–µ–ø–µ–Ω–Ω–∞—è"):
                        fit = fit_power_law(x_vals, y_vals)  # —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ X>0 –∏ Y>0
                        a, p, r2 = fit["a"], fit["p"], fit["r2"]
                        used = fit.get("used_points", 0)
                        if np.isnan(a) or np.isnan(p):
                            info_lines.append("–î–ª—è —Å—Ç–µ–ø–µ–Ω–Ω–æ–π –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ –Ω—É–∂–Ω—ã –ø–∞—Ä—ã —Å X>0 –∏ Y>0.")
                        else:
                            x_pos = x_grid[x_grid > 0]
                            y_line = a * np.power(x_pos, p)
                            fig_scatter.add_trace(go.Scatter(x=x_pos, y=y_line, mode="lines", name="–°—Ç–µ–ø–µ–Ω–Ω–∞—è –∞–ø–ø—Ä.", line=dict(color="green", width=2)))
                            info_lines.append(f"–ú–æ–¥–µ–ª—å: {y_sig} = {a:.6g}¬∑{x_sig}^{p:.6g}")
                            info_lines.append(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ—á–µ–∫: {used}")
                            info_lines.append(f"R¬≤ = {r2:.4f}" if not np.isnan(r2) else "R¬≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

                    fig_scatter.update_layout(
                        uirevision="xy_scatter_fixed_bottom",
                        height=600,
                        xaxis_title=x_sig,
                        yaxis_title=y_sig,
                        margin=dict(l=20, r=20, t=40, b=20),
                        legend_title_text="",
                    )

                    st.plotly_chart(fig_scatter, use_container_width=True)

                    if info_lines:
                        st.markdown("**–ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è:**")
                        for line in info_lines:
                            st.markdown(f"- {line}")
        



        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("–í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤", len(df_all_signals.columns))
        with col2:
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π", len(df_all_signals))
        with col3:
            try:
                dt_range = df_all_signals.index.max() - df_all_signals.index.min()
                st.metric("–î–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏", str(dt_range).split(".")[0])
            except Exception:
                st.metric("–î–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏", "‚Äî")

if CODE:
    with st.expander("üß© –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥"):
        st.code(CODE, language="text")